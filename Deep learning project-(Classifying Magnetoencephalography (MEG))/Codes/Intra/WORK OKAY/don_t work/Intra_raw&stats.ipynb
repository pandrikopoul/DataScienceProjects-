{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNT0IIx/DC4qvIdGhGLuEJ8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUD2HtuR8n5o","executionInfo":{"status":"ok","timestamp":1704665590531,"user_tz":-60,"elapsed":16559,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"3524f388-742d-45c2-ca35-f64074b2aeaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import h5py\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from scipy.signal import butter, filtfilt, lfilter\n","import matplotlib.pyplot as plt\n","import gc\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, LSTM, Dense, Flatten, BatchNormalization, Dropout, MaxPooling1D, Concatenate, Input, TimeDistributed, Reshape, Permute\n","from keras.models import Model\n","from keras.utils import to_categorical\n","from tensorflow import keras\n","import pywt\n","import scipy.signal as signal\n","from scipy.integrate import simps\n","\n","import scipy"],"metadata":{"id":"tMDH1iri8qzv","executionInfo":{"status":"ok","timestamp":1704666875263,"user_tz":-60,"elapsed":187,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ---------- FUNCTIONS ---------- #\n","\n","#___SCALING___#\n","def apply_scaling(array):\n","  array_norm = np.zeros((array.shape[0],array.shape[1]))\n","  for i in range(array.shape[0]):\n","    means = np.mean(array[i])  # Calculate mean for each sensor\n","    stds = np.std(array[i])    # Calculate standard deviation for each sensor\n","    array_norm[i] = (array[i] - means) / stds   # Subtrack and divide\n","\n","  del array, means, stds\n","  gc.collect()\n","  return array_norm\n","\n","#___LOWPASS FILTER___#\n","def butter_lowpass_filter(data, cutoff, fs, order=5):\n","    nyq = 0.5 * fs  # Nyquist Frequency\n","    normal_cutoff = cutoff / nyq\n","    # Get the filter coefficients\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    y = filtfilt(b, a, data)\n","    return y\n","\n","def apply_lowpass(array):\n","  original_sampling_rate = 2034  # Original sampling rate\n","  downsampling_factor = 4\n","  new_sampling_rate = original_sampling_rate / downsampling_factor  # New sampling rate after downsampling\n","  cutoff_frequency = new_sampling_rate / 2  # Nyquist frequency\n","\n","  array_filtered = np.zeros((array.shape[0], array.shape[1]))\n","\n","  for i in range(array.shape[0]):  # Iterate over sensors\n","      array_filtered[i, :] = butter_lowpass_filter(array[i, :], cutoff_frequency, original_sampling_rate)\n","\n","  del array\n","  return array_filtered\n","\n","#___DOWNSAMPLING___#\n","def apply_downsampling(array):\n","  n_sensors, n_timepoints = array.shape\n","\n","  downsampling_factor = 4\n","  new_n_timepoints = n_timepoints // downsampling_factor\n","  array_downsamp = np.zeros((n_sensors, new_n_timepoints))\n","\n","  for sensor in range(n_sensors):\n","    array_downsamp[sensor,:] = array[sensor, ::downsampling_factor]\n","\n","  del array, new_n_timepoints, downsampling_factor, n_sensors, n_timepoints\n","  gc.collect()\n","  return array_downsamp\n","\n","\n","#___STATS___#\n","def calculate_statistics(data):\n","    # data: numpy array of shape (timepoints,)\n","    return np.array([\n","        np.mean(data),  # Mean\n","        np.std(data),   # Standard Deviation\n","        np.max(data),   # Maximum\n","        np.min(data),   # Minimum\n","        np.mean(np.abs(np.diff(data))),  # Average absolute first difference\n","        np.mean(np.abs(np.diff(data, n=2))),  # Average absolute second difference\n","        scipy.stats.skew(data),  # Skewness\n","        scipy.stats.kurtosis(data)  # Kurtosis\n","    ])\n","\n","def extract_features_and_segment(data, num_segments):\n","    # data: numpy array of shape (records, sensors, timepoints)\n","    num_sensors, num_timepoints = data.shape\n","    segment_length = num_timepoints // num_segments\n","\n","    # Initialize array for extracted features\n","    # Shape: (records, sensors, segments, features)\n","    extracted_features = np.zeros((num_sensors, num_segments, 8))\n","\n","    for sensor in range(num_sensors):\n","        for segment in range(num_segments):\n","            start = segment * segment_length\n","            end = start + segment_length\n","            segment_data = data[sensor, start:end]\n","            extracted_features[sensor, segment] = calculate_statistics(segment_data)\n","\n","    return extracted_features\n","\n","\n"],"metadata":{"id":"q1OW8E-Z8q1w","executionInfo":{"status":"ok","timestamp":1704665620560,"user_tz":-60,"elapsed":173,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# LOAD FILES\n","\n","def get_file_paths_and_labels(data_folder, task_numbers):\n","  file_paths = []\n","  labels = []\n","  for task_number in task_numbers:\n","      for file in os.listdir(data_folder):\n","          if file.endswith(task_number + 'h5'):\n","              file_path = os.path.join(data_folder, file)\n","              file_paths.append(file_path)\n","              labels.append(assign_label(file))\n","  return file_paths, labels\n","\n","def find_fmri_data_folder(start_path):\n","    for root, dirs, files in os.walk(start_path):\n","        if 'meg_data' in dirs:\n","            return os.path.join(root, 'meg_data/Intra/train')\n","    raise Exception(\"meg_data folder not found. Please check the directory structure.\")\n","\n","def load_data(file_path):\n","  with h5py.File(file_path, 'r') as f:\n","      dataset_name = get_dataset_name(file_path)\n","      matrix = f.get(dataset_name)[:]\n","      return matrix\n","\n","def get_dataset_name(file_name_with_dir):\n","  filename_without_dir = file_name_with_dir.split('/')[-1]\n","  temp = filename_without_dir.split('_')[:-1]\n","  dataset_name = \"_\".join(temp)\n","  return dataset_name\n","\n","def assign_label(file_name):\n","  if file_name.startswith(\"rest\"):\n","      return 0\n","  elif file_name.startswith(\"task_motor\"):\n","      return 1\n","  elif file_name.startswith(\"task_story\"):\n","      return 2\n","  elif file_name.startswith(\"task_working\"):\n","      return 3\n","  else:\n","      return None\n","\n","def count_files_with_task_numbers(data_folder, task_numbers):\n","    total_files = 0\n","    for file in os.listdir(data_folder):\n","        if any(file.endswith(task_number + 'h5') for task_number in task_numbers):\n","            total_files += 1\n","    return total_files"],"metadata":{"id":"HRJXMChE8q30","executionInfo":{"status":"ok","timestamp":1704665626649,"user_tz":-60,"elapsed":204,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Call Preprocessing functions\n","def preprocess_data_1(data, i, segments):\n","  print(f\"*** FILE {i} ***\")\n","  data = apply_scaling(data)\n","  print(\"scaling applied: shape:\", data.shape, end=', ')\n","  data = apply_lowpass(data)\n","  print(\"lowpass applied: shape:\", data.shape, end=', ')\n","  data = apply_downsampling(data)\n","  print(\"downsam applied: shape:\", data.shape, end=', ')\n","  data = extract_features_and_segment(data,segments)\n","  print(\"Data after feature extraction:\", np.array(data).shape)\n","  return np.array(data)\n","\n","def preprocess_data_2(data, i):\n","  print(f\"*** FILE {i} ***\")\n","  data = apply_scaling(data)\n","  print(\"scaling applied: shape:\", data.shape, end=', ')\n","  data = apply_lowpass(data)\n","  print(\"lowpass applied: shape:\", data.shape, end=', ')\n","  data = apply_downsampling(data)\n","  print(\"downsam applied: shape:\", data.shape, end=', ')\n","  return np.array(data)"],"metadata":{"id":"CzWioXV48q5g","executionInfo":{"status":"ok","timestamp":1704665681972,"user_tz":-60,"elapsed":193,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Retieve the initial data from the folder\n","\n","fmri_data_folder = find_fmri_data_folder('/content/drive')\n","print(\"fmri_data_folder:\", fmri_data_folder)\n","\n","meg_data_list = []\n","labels = []\n","\n","for file in os.listdir(fmri_data_folder):\n","    if file.endswith('.h5'):\n","        file_path = os.path.join(fmri_data_folder, file)\n","        data = load_data(file_path)\n","        meg_data_list.append(data)\n","        labels.append(assign_label(file))\n","\n","        # Clear memory\n","        del data\n","        gc.collect()\n","\n","# Convert the list of 2D arrays into a single 3D NumPy array\n","meg_train_data_array = np.stack(meg_data_list, axis=0)\n","labels_train_array = np.array(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wyXBzw58q7G","executionInfo":{"status":"ok","timestamp":1704665742612,"user_tz":-60,"elapsed":57495,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"13673e18-3caa-4417-b45a-fa4bcfc29833"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["fmri_data_folder: /content/drive/MyDrive/Courses/Pattern Recognition/Lab/Group Assignment/meg_data/Intra/train\n"]}]},{"cell_type":"code","source":["print(\"## Initial shapes of the data ##\")\n","print(\"MEG:\", meg_train_data_array.shape)\n","print(\"Labels:\",labels_train_array.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJD7rZuH8q9A","executionInfo":{"status":"ok","timestamp":1704665749338,"user_tz":-60,"elapsed":198,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"4a782dcc-ebe7-4ea5-f6e3-3771869aecac"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["## Initial shapes of the data ##\n","MEG: (32, 248, 35624)\n","Labels: (32,)\n"]}]},{"cell_type":"code","source":["# ----- SEGMENT AND STATS ----- #\n","segments = 61\n","processed_data_stats = np.zeros((meg_train_data_array.shape[0], meg_train_data_array.shape[1], segments, 8))\n","print(processed_data_stats.shape)\n","for i in range(meg_train_data_array.shape[0]):\n","  processed_data_stats[i] = preprocess_data_1(meg_train_data_array[i], i+1, segments)"],"metadata":{"id":"7f8z5rx48q-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----- NO SEGMENT ----- #\n","processed_data = np.zeros((meg_train_data_array.shape[0], meg_train_data_array.shape[1], meg_train_data_array.shape[2]//4))\n","print(processed_data.shape)\n","for i in range(meg_train_data_array.shape[0]):\n","  processed_data[i] = preprocess_data_2(meg_train_data_array[i], i+1)"],"metadata":{"id":"BlV415z58rAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_stats = processed_data_stats\n","X_raw = processed_data\n","y_train = to_categorical(labels_train_array, num_classes=4)\n","\n","del processed_data, processed_data_stats, labels_train_array"],"metadata":{"id":"rjA2qr7z-lue","executionInfo":{"status":"ok","timestamp":1704666829203,"user_tz":-60,"elapsed":176,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(\"## Final shapes of the data ##\")\n","print(\"MEG:\", X_stats.shape, X_raw.shape)\n","print(\"Labels:\",y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q77zyg7G-lo2","executionInfo":{"status":"ok","timestamp":1704666831189,"user_tz":-60,"elapsed":267,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"952b251c-d5d4-4efb-ce9d-8b448ae31786"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["## Final shapes of the data ##\n","MEG: (32, 248, 61, 8) (32, 248, 8906)\n","Labels: (32, 4)\n"]}]},{"cell_type":"code","source":["X_stats_flat = X_stats.reshape(32, 248, -1)\n","print(X_stats_flat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBSHZu2OEfvm","executionInfo":{"status":"ok","timestamp":1704667057305,"user_tz":-60,"elapsed":183,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"57f28416-4bed-45f4-c3fe-52b55a4bba9b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 248, 488)\n"]}]},{"cell_type":"code","source":["# ----- MODEL ----- #\n","\n","def build_model(input_stats, input_raw, num_classes):\n","  # Branch for statistical data\n","  std_input = Input(shape=input_stats)\n","  print(std_input)\n","  std_branch = Dense(64, activation='relu')(std_input)\n","  std_branch = Dense(32, activation='relu')(std_branch)\n","  std_branch = Flatten()(std_branch)  # Flatten to 1D\n","\n","  # Branch for raw data\n","  raw_input = Input(shape=input_raw)\n","  print(raw_input)\n","  raw_branch = Conv1D(filters=32, kernel_size=3, activation='relu')(raw_input)\n","  raw_branch = Flatten()(raw_branch)\n","\n","  # Merge branches\n","  merged = Concatenate()([std_branch, raw_branch])\n","\n","  # Final layers\n","  merged = Dense(64, activation='relu')(merged)\n","  output = Dense(num_classes, activation='softmax')(merged)\n","\n","  # Create model\n","  model = Model(inputs=[std_input, raw_input], outputs=output)\n","\n","  # Compile and train\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"],"metadata":{"id":"JyuMDmvk8rCa","executionInfo":{"status":"ok","timestamp":1704669030022,"user_tz":-60,"elapsed":214,"user":{"displayName":"Christos","userId":"17488364610072087916"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["print(\"X_stats_flat shape:\", X_stats_flat.shape)\n","print(\"X_raw shape:\", X_raw.shape)\n","print(\"Labels shape:\", y_train.shape)\n","\n","print(\"X_stats_flat shape:\", type(X_stats_flat))\n","print(\"X_raw shape:\", type(X_raw))\n","print(\"Labels shape:\", type(y_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wds15PMZHAcV","executionInfo":{"status":"ok","timestamp":1704667704413,"user_tz":-60,"elapsed":178,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"a37c4b40-0cc6-405e-db49-396369a61a3a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["X_stats_flat shape: (32, 248, 488)\n","X_raw shape: (32, 248, 8906)\n","Labels shape: (32, 4)\n","X_stats_flat shape: <class 'numpy.ndarray'>\n","X_raw shape: <class 'numpy.ndarray'>\n","Labels shape: <class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["model = build_model((X_stats_flat.shape[1], X_stats_flat.shape[2]), (X_raw.shape[1], X_raw.shape[2]), 4)\n","print((X_stats_flat.shape[1], X_stats_flat.shape[2]), (X_raw.shape[1], X_raw.shape[2]))\n","print(model)\n","history = model.fit([X_stats_flat, X_raw], labels, epochs=10, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"g9Aen_AS8rEJ","executionInfo":{"status":"error","timestamp":1704669045704,"user_tz":-60,"elapsed":602,"user":{"displayName":"Christos","userId":"17488364610072087916"}},"outputId":"27648ae8-b953-4e59-a47d-47458c869cff"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 248, 488), dtype=tf.float32, name='input_35'), name='input_35', description=\"created by layer 'input_35'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 248, 8906), dtype=tf.float32, name='input_36'), name='input_36', description=\"created by layer 'input_36'\")\n","(248, 488) (248, 8906)\n","<keras.src.engine.functional.Functional object at 0x7e54001d75b0>\n"]},{"output_type":"error","ename":"ValueError","evalue":"Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-334220fd277a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_stats_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_stats_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_stats_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tPv-wsdl8rF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zibEoAbN8rH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hVDZEddx8rJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eg00fVUq8rLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vPiZMB-J8rPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nn_ovTFv8rRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IV_17NRx8rSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7IMqqFoB8rV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6wgyVp2E8rZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qkNDTaKB8rbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eZlZeM3s8rdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2C5EUBiI8rfb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JwXGdJwC8rhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RU5OkuG08rjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RAtWtnsE8ruE"},"execution_count":null,"outputs":[]}]}