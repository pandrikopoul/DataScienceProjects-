{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d260f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in d:\\anaconda\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in d:\\anaconda\\lib\\site-packages (from rdflib) (3.0.9)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c8a5af-e9e8-40fb-b58c-8bb61879c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdflib import Graph, Literal, RDF, URIRef\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12c13e1-c76d-4b74-bb0b-ef06fa3eccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ttl_file(file_path):\n",
    "    graph = Graph()\n",
    "    graph.parse(file_path, format=\"turtle\")\n",
    "    # Extract triples from the graph\n",
    "    triples = [(str(s), str(p), str(o)) for s, p, o in graph]\n",
    "    return triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef7bcee-af68-41e3-8178-6251ddc3d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(triples, entity_to_index, relation_to_index):\n",
    "    triple_indices = [\n",
    "        (entity_to_index[s], relation_to_index[p], entity_to_index[o])\n",
    "        for s, p, o in triples\n",
    "    ]\n",
    "    tensor_data = torch.tensor(triple_indices, dtype=torch.long)\n",
    "    return tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da643db-dc0f-4487-abb0-d3aa32989ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNumOfUniqueValues(data):\n",
    "    unique_entities =set()\n",
    "    unique_relations =set()\n",
    "    for triple in data:\n",
    "        unique_entities.add(triple[0])  # Subject\n",
    "        unique_relations.add(triple[1]) # Predicate (relation)\n",
    "        unique_entities.add(triple[2])  # Object\n",
    "    \n",
    "    # Count the number of unique entities\n",
    "    num_entities = len(unique_entities)\n",
    "    num_relations = len(unique_relations)\n",
    "    print(f\"Number of unique entities: {num_entities}\")\n",
    "    print(f\"Number of unique relations: {num_relations}\")\n",
    "    return num_entities,num_relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b5f619-c8cf-4e9c-bc21-4434a52fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransEModel(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(TransEModel, self).__init__()\n",
    "        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)\n",
    "\n",
    "    def forward(self, triples):\n",
    "        # Ensure indices are within the valid range\n",
    "        num_entities = self.entity_embedding.weight.size(0)\n",
    "        num_relations = self.relation_embedding.weight.size(0)\n",
    "        \n",
    "        subject_indices = torch.clamp(triples[:, 0], max=num_entities - 1)\n",
    "        relation_indices = torch.clamp(triples[:, 1], max=num_relations - 1)\n",
    "        object_indices = torch.clamp(triples[:, 2], max=num_entities - 1)\n",
    "        \n",
    "        subject_embedding = self.entity_embedding(subject_indices)\n",
    "        relation_embedding = self.relation_embedding(relation_indices)\n",
    "        object_embedding = self.entity_embedding(object_indices)\n",
    "        \n",
    "        score = torch.sum(torch.abs(subject_embedding + relation_embedding - object_embedding), dim=1)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f56c6b7-06f6-4bb2-8ea5-c5ecae299df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MyDataset\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triples[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e85daf-aaf8-46ff-874a-9a8d1030a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataLoader for negative triplets\n",
    "class NegativeTripletsDataset(Dataset):\n",
    "    def __init__(self, positive_triples, num_entities):\n",
    "        self.positive_triples = positive_triples\n",
    "        self.num_entities = num_entities\n",
    "    def __len__(self):\n",
    "        return len(self.positive_triples)\n",
    "    def __getitem__(self, idx):\n",
    "        return create_negative_triples(self.positive_triples[idx], self.num_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ed42df-7a74-4867-a228-88692ed52a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_triples(positive_triples, num_entities, device):\n",
    "    batch_size = positive_triples.size(0)\n",
    "    # Generate random indices for negative subjects and objects\n",
    "    negative_subjects = torch.randint(0, num_entities, (batch_size,)).to(device)\n",
    "    negative_objects = torch.randint(0, num_entities, (batch_size,)).to(device)\n",
    "    \n",
    "    # Clone positive triples to create negative triples\n",
    "    negative_triples = positive_triples.clone()\n",
    "\n",
    "    # Replace either subject or object in each positive triple with a negative entity\n",
    "    replace_subject = torch.rand(batch_size).to(device) > 0.5\n",
    "    negative_triples[:, 0] = torch.where(replace_subject, negative_subjects, negative_triples[:, 0])\n",
    "    negative_triples[:, 2] = torch.where(~replace_subject, negative_objects, negative_triples[:, 2])\n",
    "    \n",
    "    return negative_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2772319a-1d3c-4c24-8616-df628f83ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_data in data_loader:\n",
    "            positive_scores = model(batch_data.to(device))\n",
    "\n",
    "            # Generate negative triples\n",
    "            negative_triples = create_negative_triples(batch_data, num_entities, device)\n",
    "            negative_scores = model(negative_triples)\n",
    "\n",
    "            # Ensure consistent batch size\n",
    "            target = torch.ones(positive_scores.size(0)).to(device)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(positive_scores, negative_scores, target)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        average_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e39ad17-d842-43f6-acbe-d032dc00484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data_loader, num_entities, k_values=[1, 3, 5, 10]):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_data_loader:\n",
    "            positive_scores = model(batch_data.to(device))\n",
    "            # Create negative triples by corrupting positive triples\n",
    "            negative_triples = create_negative_triples(batch_data, num_entities,device)\n",
    "            negative_scores = model(negative_triples)\n",
    "            # Concatenate positive and negative scores\n",
    "            batch_scores = torch.cat([positive_scores, negative_scores])\n",
    "            all_scores.append(batch_scores)\n",
    "            # Create labels (1 for positive, 0 for negative)\n",
    "            batch_labels = torch.cat([torch.ones_like(positive_scores), torch.zeros_like(negative_scores)])\n",
    "            all_labels.append(batch_labels)\n",
    "\n",
    "    # Concatenate scores and labels across batches\n",
    "    all_scores = torch.cat(all_scores)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Print dimensions for debugging\n",
    "    print(\"Dimensions:\")\n",
    "    print(\"y_true:\", all_labels.cpu().detach().numpy().shape)\n",
    "    print(\"y_score:\", all_scores.cpu().detach().numpy().shape)\n",
    "    # Calculate Hits@k\n",
    "    hits_at_k = {}\n",
    "    sorted_indices = torch.argsort(positive_scores, descending=True)\n",
    "    for k in k_values:\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        hits_at_k[k] = torch.sum(top_k_indices < len(positive_scores)).item() / len(positive_scores)\n",
    "    # Calculate precision-recall metrics\n",
    "    ap_score = average_precision_score(all_labels.cpu().detach().numpy(), all_scores.cpu().detach().numpy())\n",
    "    print(f'Average Precision (AP): {ap_score:.4f}')\n",
    "    for k in k_values:\n",
    "        print(f'Hits@{k}: {hits_at_k[k]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fae1a2-8a5e-4fb7-9e0c-09dede4413fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entities: 257222\n",
      "Number of unique relations: 189\n"
     ]
    }
   ],
   "source": [
    "#initializing the variables\n",
    "batch_size = 64\n",
    "random_seed = 42\n",
    "embedding_dim = 100\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Reading the data (we fucused only on formula 1 data)\n",
    "f1_file_path = \"FormulaOne_FinalOutPut.ttl\"\n",
    "data = read_ttl_file(f1_file_path)\n",
    "\n",
    "# Creating the train and test sets\n",
    "train_triples, test_triples = train_test_split(data, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Calculating the number of entities and relations\n",
    "num_entities,num_relations = calculateNumOfUniqueValues(train_triples)\n",
    "\n",
    "# Transforming the entities and relations into dictionaries that are compatible with our class\n",
    "entity_to_index = {entity: index for index, entity in enumerate(set([s for s, _, _ in data] + [o for _, _, o in data]))}\n",
    "relation_to_index = {relation: index for index, relation in enumerate(set([p for _, p, _ in data]))}\n",
    "\n",
    "# Converting the data into a tensors format\n",
    "tensor_data = convert_to_tensors(train_triples, entity_to_index, relation_to_index).to(device)\n",
    "dataset = MyDataset(tensor_data)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initializing the model according to number of relations and entities\n",
    "model = TransEModel(num_entities, num_relations, embedding_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08d0382-aba2-481e-8c1c-c96c817062cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for negative triplets\n",
    "negative_triplets_dataset = NegativeTripletsDataset(tensor_data, num_entities)\n",
    "negative_triplets_loader = DataLoader(negative_triplets_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba33770-55c9-4190-9724-c575f7bb7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "criterion = nn.MarginRankingLoss(margin=1.0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a2839e-86f6-4a97-9852-d831cc1c04fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 3.2504\n",
      "Epoch 2/10, Average Loss: 2.1872\n",
      "Epoch 3/10, Average Loss: 1.7438\n",
      "Epoch 4/10, Average Loss: 1.4729\n",
      "Epoch 5/10, Average Loss: 1.2859\n",
      "Epoch 6/10, Average Loss: 1.1335\n",
      "Epoch 7/10, Average Loss: 1.0138\n",
      "Epoch 8/10, Average Loss: 0.9178\n",
      "Epoch 9/10, Average Loss: 0.8334\n",
      "Epoch 10/10, Average Loss: 0.7605\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92ebe8c2-ca6a-4a16-801f-ff17fe0408ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entities: 169585\n",
      "Number of unique relations: 189\n",
      "Dimensions:\n",
      "y_true: (772754,)\n",
      "y_score: (772754,)\n",
      "Average Precision (AP): 0.7121\n",
      "Hits@1: 0.1111\n",
      "Hits@3: 0.3333\n",
      "Hits@5: 0.5556\n",
      "Hits@10: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Transforming the test set into a data loader\n",
    "test_batch_size = 64\n",
    "test_tensor_data = convert_to_tensors(test_triples, entity_to_index, relation_to_index).to(device)\n",
    "test_data_loader = DataLoader(test_tensor_data, batch_size=test_batch_size, shuffle=False)\n",
    "# Evaluate the model\n",
    "num_entities_test,num_relations_test = calculateNumOfUniqueValues(test_triples)\n",
    "evaluate_model(model, test_data_loader,num_entities_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b6a79a-c3d9-4883-a936-16cd63bdd8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: 115523 103 120252\n",
      "Positive Score: [183.40065]\n",
      "Negative Score: 134.9213104248047\n",
      "The exsistance of such triple according to our model is: Positive\n"
     ]
    }
   ],
   "source": [
    "example_triple = (\"27\", 'http://example.org/motor-sports/formula-one/sprint_results/status', \"20\")\n",
    "\n",
    "subject_idx = entity_to_index.get(example_triple[0], -1)\n",
    "relation_idx = relation_to_index.get(example_triple[1], -1)\n",
    "object_idx = entity_to_index.get(example_triple[2], -1)\n",
    "\n",
    "print(\"Indices:\", subject_idx, relation_idx, object_idx)\n",
    "\n",
    "if subject_idx == -1 or relation_idx == -1 or object_idx == -1:\n",
    "    print(\"One or more entities/relations wasn't found -> Unable to evaluate.\")\n",
    "else:\n",
    "    # Transforming the triple into tensor format\n",
    "    custom_triple_tensor = torch.tensor([[subject_idx, relation_idx, object_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    # Predict the score for the positive (true) triple\n",
    "    positive_score = model(custom_triple_tensor).detach().cpu().numpy()\n",
    "\n",
    "    # Corrupt the triple to create a negative example\n",
    "    negative_subject = torch.randint(0, num_entities, (1,)).item()\n",
    "    negative_object = torch.randint(0, num_entities, (1,)).item()\n",
    "\n",
    "    negative_triple_tensor = torch.tensor([[negative_subject, relation_idx, negative_object]], dtype=torch.long).to(device)\n",
    "\n",
    "    # Predict the score for the negative triple\n",
    "    negative_score = model(negative_triple_tensor).item()\n",
    "\n",
    "    print(\"Positive Score:\", positive_score)\n",
    "    print(\"Negative Score:\", negative_score)\n",
    "\n",
    "    # Print the prediction\n",
    "    prediction = \"Positive\" if positive_score > negative_score else \"Negative\"\n",
    "    print(f\"The exsistance of such triple according to our model is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db5f38d-6c36-4676-8dd3-b25492fbd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k Predictions: ['turbo']\n"
     ]
    }
   ],
   "source": [
    "# example query (subject -> constructor:27 , predicate -> status , object -> ?)\n",
    "query_triple = (\"http://example.org/motor-sports/formula-one/constructors/27\", 'http://example.org/motor-sports/formula-one/sprint_results/status', None)\n",
    "\n",
    "# Get indices for subject and relation\n",
    "subject_idx = entity_to_index.get(query_triple[0], -1)\n",
    "relation_idx = relation_to_index.get(query_triple[1], -1)\n",
    "\n",
    "if subject_idx != -1 and relation_idx != -1:\n",
    "    # Create tensor for the given subject and relation\n",
    "    input_tensor = torch.tensor([[subject_idx, relation_idx, 0]], dtype=torch.long).to(device)\n",
    "\n",
    "    # Predict the scores for all objects\n",
    "    object_scores = model(input_tensor).detach().cpu().numpy()\n",
    "\n",
    "    # Get the indices of the top-k predictions\n",
    "    k = 1\n",
    "    top_k_indices = torch.topk(torch.tensor(object_scores), k=k).indices.numpy()\n",
    "\n",
    "    # Convert indices back to entity names using entity_to_index dictionary\n",
    "    top_k_entities = [key for key, value in entity_to_index.items() if value in top_k_indices]\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Top-k Predictions:\", top_k_entities)\n",
    "else:\n",
    "    print(\"One or more entities/relations not found in the mapping. Unable to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b6bbc-f6c7-47bf-81b4-4989b52a3336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
